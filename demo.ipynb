{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "It's difficult to use functions in jupyter notebook, since we want different steps to be in different cells, so one of the main functions of this module is to emulate a function like scope of the variables - which get destroyed at the end of the experiment. Some extra magic is added to reclaim GPU and General RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup && Preload\n",
    "\n",
    "Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_gpu(n): return torch.ones((n, n)).cuda()\n",
    "def consume_cpu(n): return np.ones((n, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch` seems to latch on ~0.5GB GPU RAM, and ~2GB of RAM upon its first use, so let's pre-load it, so that the experiments' stats are not misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = consume_gpu(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Consume General RAM\n",
    "\n",
    "Let's consume a big chunk of non-GPU RAM and reclaim it at the end of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n"
     ]
    }
   ],
   "source": [
    "exp1 = IPyExperiments() # consume some cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x2', 'x1']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 4.3 GB\n",
      "GPU: 0 Bytes\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 4.3 GB (100.00%)\n",
      "GPU: 0 Bytes (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n"
     ]
    }
   ],
   "source": [
    "del exp1 # finish experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Consume General and GPU RAM\n",
    "\n",
    "Let's consume a big chunk of non-GPU and GPU RAM and reclaim both at the end of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n"
     ]
    }
   ],
   "source": [
    "exp2 = IPyExperiments() # consume some gpu and cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_gpu(2**14) # about 1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x2', 'x1']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n"
     ]
    }
   ],
   "source": [
    "del exp2 # finish experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Get Stats Data\n",
    "\n",
    "Here we demonstate features that help with using this framework programmatically. i.e. getting the functions to return stats during and at the end of the experiment, rather than just printing it. You can then use it to programmatically refine the parameters before rerunning the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n"
     ]
    }
   ],
   "source": [
    "exp3 = IPyExperiments() # consume some gpu and cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an intermediary report of how much of the resources was consumed, and how much is available, returning the data as numbers. (none would be reclaimed yet, so it'll be zeros, but the return value is there for consistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_ram': 2147504128, 'gpu_ram': 0} {'gen_ram': 0, 'gpu_ram': 0} {'gen_ram': 9627705344, 'gpu_ram': 7487881216}\n"
     ]
    }
   ],
   "source": [
    "consumed, reclaimed, available = exp3.get_stats()\n",
    "print(consumed, reclaimed, available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_gpu(2**14) # about 1GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run another intermediary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_ram': 2147528704, 'gpu_ram': 1073741824} {'gen_ram': 0, 'gpu_ram': 0} {'gen_ram': 9625780224, 'gpu_ram': 6414139392}\n"
     ]
    }
   ],
   "source": [
    "consumed, reclaimed, available = exp3.get_stats()\n",
    "print(consumed, reclaimed, available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the final report of how much of the resources was consumed, and how much is available, and how much was reclaimed, returning the data as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['reclaimed', 'x1', 'consumed', 'available', 'exp3', 'x2']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 11.8 GB | Proc size 2.1 GB\n",
      "GPU RAM Free  7.5 GB | Used 1.0 GB | Util 12.0% | Total 8.5 GB\n",
      "\n",
      "Numerical data:\n",
      " {'gen_ram': 2147532800, 'gpu_ram': 1073741824} {'gen_ram': 2147483648, 'gpu_ram': 1073741824} {'gen_ram': 11776757760, 'gpu_ram': 7487881216}\n"
     ]
    }
   ],
   "source": [
    "final_consumed, final_reclaimed, final_available = exp3.finish() # finish experiment\n",
    "print(\"\\nNumerical data:\\n\", final_consumed, final_reclaimed, final_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
