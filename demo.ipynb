{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "It's difficult to use functions in jupyter notebook, since we want different steps to be in different cells, so one of the main functions of this module is to emulate a function like scope of the variables - which get destroyed at the end of the experiment. Some extra magic is added to reclaim GPU and General RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_gpu(n): return torch.ones((n, n)).cuda()\n",
    "def consume_cpu(n): return np.ones((n, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch`'s CUDA machinery seems to require ~0.5GB GPU RAM, and ~2GB of RAM upon its first use, and it's not shared between processes. So if you use pytorch w/ CUDA your GPU card is 0.5GB smaller from the get going, and multiply that by the number of concurrent processes. \n",
    "\n",
    "Because of that, in order to get the numbers right, let's pre-load it by allocating a tiny tensor on `cuda`. If we don't - the first experiments' stats will be misleading/incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = consume_gpu(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Consume general RAM\n",
    "\n",
    "Let's consume a big chunk of non-GPU RAM and reclaim it at the end of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 15.0 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp1 = IPyExperiments() # consume some cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x1', 'x2']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 4.3 GB\n",
      "GPU: 0 Bytes\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 4.3 GB (100.00%)\n",
      "GPU: 0 Bytes (100.00%)\n",
      "\n",
      "*** Elapsed wallclock time:\n",
      "00:00:01\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del exp1 # finish experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Consume general and GPU RAM\n",
    "\n",
    "Let's consume a big chunk of non-GPU and GPU RAM and reclaim both at the end of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp2 = IPyExperiments() # consume some gpu and cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_gpu(2**14) # about 1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x1', 'x2']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.00%)\n",
      "\n",
      "*** Elapsed wallclock time:\n",
      "00:00:01\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del exp2 # finish experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Get stats data, preserve some vars\n",
    "\n",
    "Here we demonstate features that help with using this framework programmatically. i.e. getting the functions to return stats during and at the end of the experiment, rather than just printing it. You can then use it to programmatically refine the parameters before rerunning the experiment.\n",
    "\n",
    "This experiment also demonstrates how to save some of the local variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp3 = IPyExperiments() # consume some gpu and cpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = consume_cpu(2**14) # about 1.5GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an intermediary report of how much of the resources was consumed, and how much is available, returning the data as numbers. (none would be reclaimed yet, so it'll be zeros, but the return value is there for consistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_ram': 2147504128, 'gpu_ram': 0} {'gen_ram': 0, 'gpu_ram': 0} {'gen_ram': 12794216448, 'gpu_ram': 7996440576}\n"
     ]
    }
   ],
   "source": [
    "consumed, reclaimed, available = exp3.get_stats()\n",
    "print(consumed, reclaimed, available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preserve these variables, so that they remain available after the experiment is finished and the rest of the local variables get deleted. \n",
    "\n",
    "Note, that you need to pass the names of the variables and not the variables themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3.keep_var_names('consumed', 'reclaimed', 'available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = consume_gpu(2**14) # about 1GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run another intermediary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_ram': 2147504128, 'gpu_ram': 1073741824} {'gen_ram': 0, 'gpu_ram': 0} {'gen_ram': 12793061376, 'gpu_ram': 6922698752}\n"
     ]
    }
   ],
   "source": [
    "consumed, reclaimed, available = exp3.get_stats()\n",
    "print(consumed, reclaimed, available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the experiment, delete local vars, reclaim memory, and run the final report of how much of the resources was consumed, and how much is available, and how much was reclaimed, returning the data as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x1', 'exp3', 'x2']\n",
      "\n",
      "*** Keeping the following local variables:\n",
      "['consumed', 'reclaimed', 'available']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.00%)\n",
      "\n",
      "*** Elapsed wallclock time:\n",
      "00:00:01\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n",
      "\n",
      "Numerical data:\n",
      " {'gen_ram': 2147504128, 'gpu_ram': 1073741824} {'gen_ram': 2147487744, 'gpu_ram': 1073741824} {'gen_ram': 14942650368, 'gpu_ram': 7996440576}\n"
     ]
    }
   ],
   "source": [
    "final_consumed, final_reclaimed, final_available = exp3.finish() # finish experiment\n",
    "print(\"\\nNumerical data:\\n\", final_consumed, final_reclaimed, final_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's test that we can still access the variables we asked not to destroy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Half-way data:\n",
      " {'gen_ram': 2147504128, 'gpu_ram': 1073741824} {'gen_ram': 0, 'gpu_ram': 0} {'gen_ram': 12793061376, 'gpu_ram': 6922698752}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHalf-way data:\\n\", consumed, reclaimed, available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Context manager\n",
    "\n",
    "If you want to put all cells into one, you could simplify the experiment even further by using its context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n",
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['x1', 'x2']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.00%)\n",
      "\n",
      "*** Elapsed wallclock time:\n",
      "00:00:01\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with IPyExperiments(): \n",
    "    x1 = consume_cpu(2**14)\n",
    "    x2 = consume_gpu(2**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 516.9 MB | Util 6.1% | Total 8.5 GB\n",
      "\n",
      "\n",
      "Finishing experiment...\n",
      "\n",
      "*** Deleting the following local variables:\n",
      "['exp', 'x1', 'x2']\n",
      "\n",
      "*** Keeping the following local variables:\n",
      "['z']\n",
      "\n",
      "*** RAM consumed during the experiment:\n",
      "Gen: 2.1 GB\n",
      "GPU: 1.1 GB\n",
      "\n",
      "*** RAM reclaimed at the end of the experiment:\n",
      "Gen: 2.1 GB (100.00%)\n",
      "GPU: 1.1 GB (100.20%)\n",
      "\n",
      "*** Elapsed wallclock time:\n",
      "00:00:01\n",
      "\n",
      "*** Current state:\n",
      "Gen RAM Free 14.9 GB | Proc size 2.2 GB\n",
      "GPU RAM Free  8.0 GB | Used 514.9 MB | Util 6.0% | Total 8.5 GB\n",
      "\n",
      "\n",
      "some data\n"
     ]
    }
   ],
   "source": [
    "with IPyExperiments() as exp: \n",
    "    x1 = consume_cpu(2**14)\n",
    "    z = \"some data\"\n",
    "    x2 = consume_gpu(2**14)\n",
    "    exp.keep_var_names('z')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prevent committing an unsaved notebook\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
